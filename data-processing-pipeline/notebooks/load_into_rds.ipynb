{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import logging\n",
    "import psycopg2\n",
    "import json\n",
    "import sys\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['processed_p18_19_5',\n 'p18_19_0',\n 'p18_19_1',\n 'p18_19_3',\n 'p18_19_5',\n 'qld_p18_19',\n 'qld_all',\n 'parameters']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-18 21:24:18,504 - kedro.io.data_catalog - INFO - Loading data from 'processed_p18_19_5' (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "df = catalog.load('processed_p18_19_5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "table_name = 'processed_p18_19_5'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Other_entities': 'TEXT',\n 'Headcount_Female': 'INTEGER',\n 'Headcount_Male': 'INTEGER',\n 'Headcount_Total': 'INTEGER',\n 'Percentage_Female': 'INTEGER',\n 'Percentage_Male': 'INTEGER'}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dict = {col: \"TEXT\" if dtype == \"object\" else \"INTEGER\" for col, dtype in df.dtypes.items()}\n",
    "column_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'Other_entities TEXT, Headcount_Female INTEGER, Headcount_Male INTEGER, Headcount_Total INTEGER, Percentage_Female INTEGER, Percentage_Male INTEGER'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the columns string for the SQL query\n",
    "columns = ', '.join(f\"{k} {v}\" for k, v in column_dict.items())\n",
    "columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Legal Aid Queensland',\n  480,\n  143,\n  623,\n  0.7704654895666132,\n  0.2295345104333868),\n ('Office of the Health Ombudsman',\n  100,\n  42,\n  142,\n  0.704225352112676,\n  0.2957746478873239),\n ('Queensland Art Gallery',\n  234,\n  131,\n  365,\n  0.6410958904109589,\n  0.3589041095890411),\n ('Queensland Family and Child Commission',\n  56,\n  17,\n  73,\n  0.7671232876712328,\n  0.2328767123287671),\n ('Queensland Human Rights Commission',\n  35,\n  9,\n  44,\n  0.7954545454545454,\n  0.2045454545454545),\n ('Queensland Museum', 219, 110, 329, 0.6656534954407295, 0.3343465045592705),\n ('Resources Safety and Health Queensland',\n  120,\n  176,\n  296,\n  0.4054054054054054,\n  0.5945945945945946),\n ('State Library of Queensland',\n  255,\n  98,\n  353,\n  0.7223796033994334,\n  0.2776203966005666),\n ('Trade and Investment Queensland',\n  83,\n  52,\n  135,\n  0.6148148148148148,\n  0.3851851851851852),\n ('Sector sub-total: Other entities',\n  1582,\n  778,\n  2360,\n  0.6703389830508475,\n  0.3296610169491525),\n ('Sector total',\n  194358,\n  85689,\n  280047,\n  0.6940192182026589,\n  0.3059807817973412)]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the DataFrame to a list of tuples\n",
    "values = [tuple(row) for row in df.to_numpy()]\n",
    "values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<cell line: 1>\u001B[0m:\u001B[94m1\u001B[0m                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1 column_names = \u001B[96mlist\u001B[0m(column_dict.keys().lowercase())                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2 \u001B[0mcolumn_names                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m3 \u001B[0m                                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m4 \u001B[0m                                                                                             \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mAttributeError: \u001B[0m\u001B[32m'dict_keys'\u001B[0m object has no attribute \u001B[32m'lowercase'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 column_names = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(column_dict.keys().lowercase())                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>column_names                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'dict_keys'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'lowercase'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_names = list(column_dict.keys())\n",
    "column_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use string interpolation to dynamically generate the SQL statement to insert the data\n",
    "values_sql = ','.join(['%s'] * len(values)[0])\n",
    "values_sql"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Generate a placeholder string. The placeholder represent one tuple of values.\n",
    "placeholders = sql.SQL(', ').join(sql.Placeholder() * len(values)[0])\n",
    "\n",
    "# SQL quert to execute\n",
    "query = sql.SQL(\"INSERT INTO {} ({}) VALUES ({})\").format(\n",
    "    sql.Identifier(table_name),\n",
    "    sql.SQL(', ').join(map(sql.Identifier, column_names)),\n",
    "    placeholders\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Composed([SQL('INSERT INTO '), Identifier('processed_p18_19_5'), SQL(' ('), Composed([Identifier('Other_entities, Headcount_Female, Headcount_Male, Headcount_Total, Percentage_Female, Percentage_Male')]), SQL(') VALUES ('), Composed([Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder(), SQL(', '), Placeholder()]), SQL(')')])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_into_rds(df):\n",
    "    \"\"\"\n",
    "    This function creates a new rds database table and writes records to it\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the secret\n",
    "    client = boto3.client('secretsmanager')\n",
    "    response = client.get_secret_value(SecretId='credentials')\n",
    "    secret = response['SecretString']\n",
    "\n",
    "    # RDS settings\n",
    "    rds_host = \"terraform-20230412032239110300000001.cz9iamvdbbik.ap-southeast-2.rds.amazonaws.com\"\n",
    "    user_name = \"gundalai\"\n",
    "    password = secret\n",
    "    db_name = \"data_store\"\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create the database connection\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=rds_host, user=user_name, password=password, database=db_name, connect_timeout=5)\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        logger.error(\"ERROR: Unexpected error: Could not connect to PostgreSQL instance.\")\n",
    "        logger.error(e)\n",
    "        sys.exit()\n",
    "\n",
    "    logger.info(\"SUCCESS: Connection to rds PostgreSQL instance succeeded\")\n",
    "\n",
    "\n",
    "    # Define the table name and column names/types based on the DataFrame's name and columns\n",
    "    table_name = 'processed_p18_19_5'\n",
    "    columns = {col: \"varchar(255)\" if dtype == \"object\" else \"integer\" for col, dtype in df.dtypes.items()}\n",
    "\n",
    "    # Convert the DataFrame to a list of tuples\n",
    "    values = [tuple(row) for row in df.to_numpy()]\n",
    "\n",
    "    # Add the dataframe as a SQL table\n",
    "    item_count = 0\n",
    "    # Use string interpolation to dynamically generate the SQL statement to insert the data\n",
    "    values_sql = ','.join(['%s'] * len(values))\n",
    "    sql_string = f\"INSERT INTO {table_name} ({', '.join(columns.keys())}) VALUES ({values_sql})\"\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            # TODO add attributes\n",
    "            f\"CREATE TABLE if not exists {table_name} ({', '.join(columns.keys())})\")\n",
    "        cur.executemany(sql_string, values)\n",
    "        conn.commit()\n",
    "        cur.execute(f\"SELECT * FROM {table_name}\")\n",
    "        logger.info(\"The following items have been added to the database:\")\n",
    "        for row in cur:\n",
    "            item_count += 1\n",
    "            logger.info(row)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Added %d items to rds PostgreSQL table\" % (item_count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lambda function that tests if it can connect and retrieve a credential from a secrets manager using boto3\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import psycopg2\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def get_secret():\n",
    "\n",
    "    secret_name = \"db_credentials\"\n",
    "    region_name = \"ap-southeast-2\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "\n",
    "    # Your code goes here.\n",
    "    return secret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        secret = get_secret()\n",
    "        print(\"Secret retrieved\")\n",
    "        sm_response_body = \"Successfully retrieved secret from Secrets Manager.\"\n",
    "        status_code = 200\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "        sm_response_body = f\"Failed to retrieve secret from Secrets Manager: {str(e)}\"\n",
    "        status_code = 500\n",
    "\n",
    "    # RDS settings\n",
    "    rds_host = \"terraform-20230509135541811400000001.cz9iamvdbbik.ap-southeast-2.rds.amazonaws.com\"\n",
    "    user_name = \"gundalai\"\n",
    "    password = secret\n",
    "    db_name = \"data_store\"\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create the database connection\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=rds_host, user=user_name, password=password, database=db_name, connect_timeout=5)\n",
    "        rds_response_body = \"Successfully connected to PostgreSQL instanse\"\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        logger.error(\"ERROR: Unexpected error: Could not connect to PostgreSQL instance.\")\n",
    "        logger.error(e)\n",
    "        rds_response_body = \"ERROR: Unexpected error: Could not connect to PostgreSQL instance.\"\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "    message = event['Records'][0]['body']\n",
    "    data = json.loads(message)\n",
    "    CustID = data['CustID']\n",
    "    Name = data['Name']\n",
    "\n",
    "    item_count = 0\n",
    "    sql_string = f\"insert into Customer (CustID, Name) values({CustID}, '{Name}')\"\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"create table if not exists Customer ( CustID  int NOT NULL, Name varchar(255) NOT NULL, PRIMARY KEY (CustID))\")\n",
    "        cur.execute(sql_string)\n",
    "        conn.commit()\n",
    "        cur.execute(\"select * from Customer\")\n",
    "        logger.info(\"The following items have been added to the database:\")\n",
    "        for row in cur:\n",
    "            item_count += 1\n",
    "            logger.info(row)\n",
    "    conn.commit()\n",
    "\n",
    "    db_response_body = \"Added %d items to RDS PostgreSQL table\" % (item_count)\n",
    "\n",
    "    return {\n",
    "        'statusCode': status_code,\n",
    "        'sm_body': json.dumps(sm_response_body),\n",
    "        'rds_body': json.dumps(rds_response_body),\n",
    "        'db_body' : json.dumps(db_response_body)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lambda function that tests if it can connect and retrieve a credential from a secrets manager using boto3\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import psycopg2\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_secret():\n",
    "\n",
    "    secret_name = \"db_credentials\"\n",
    "    region_name = \"ap-southeast-2\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "\n",
    "    # Your code goes here.\n",
    "    return secret\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Extract the bucket and object key from the event\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "\n",
    "    print(bucket)\n",
    "    print(key)\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        csv_bytes = response['Body'].read()\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(io.BytesIO(csv_bytes))\n",
    "        print(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving file from S3: {str(e)}\")\n",
    "\n",
    "    try:\n",
    "        secret = get_secret()\n",
    "        print(\"Secret retrieved\")\n",
    "        sm_response_body = \"Successfully retrieved secret from Secrets Manager.\"\n",
    "        status_code = 200\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred:\", e)\n",
    "        sm_response_body = f\"Failed to retrieve secret from Secrets Manager: {str(e)}\"\n",
    "        status_code = 500\n",
    "\n",
    "    # RDS settings\n",
    "    rds_host = \"terraform-20230509135541811400000001.cz9iamvdbbik.ap-southeast-2.rds.amazonaws.com\"\n",
    "    user_name = \"gundalai\"\n",
    "    password = secret\n",
    "    db_name = \"data_store\"\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create the database connection\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=rds_host, user=user_name, password=password, database=db_name, connect_timeout=5)\n",
    "        rds_response_body = \"Successfully connected to PostgreSQL instanse\"\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        logger.error(\"ERROR: Unexpected error: Could not connect to PostgreSQL instance.\")\n",
    "        logger.error(e)\n",
    "        rds_response_body = \"ERROR: Unexpected error: Could not connect to PostgreSQL instance.\"\n",
    "        sys.exit()\n",
    "\n",
    "    # Define the table name and column names/types based on the DataFrame's name and columns\n",
    "    table_name = 'processed_p18_19_5'\n",
    "    columns = {col: \"varchar(255)\" if dtype == \"object\" else \"integer\" for col, dtype in df.dtypes.items()}\n",
    "\n",
    "    # Convert the DataFrame to a list of tuples\n",
    "    values = [tuple(row) for row in df.to_numpy()]\n",
    "\n",
    "    # Add the dataframe as a SQL table\n",
    "    item_count = 0\n",
    "    # Use string interpolation to dynamically generate the SQL statement to insert the data\n",
    "    values_sql = ','.join(['%s'] * len(values))\n",
    "    sql_string = f\"INSERT INTO {table_name} ({', '.join(columns.keys())}) VALUES ({values_sql})\"\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            # TODO add attributes\n",
    "            f\"CREATE TABLE if not exists {table_name} ({', '.join(columns.keys())})\")\n",
    "        cur.executemany(sql_string, values)\n",
    "        conn.commit()\n",
    "        cur.execute(f\"SELECT * FROM {table_name}\")\n",
    "        logger.info(\"The following items have been added to the database:\")\n",
    "        for row in cur:\n",
    "            item_count += 1\n",
    "            logger.info(row)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Added %d items to rds PostgreSQL table\" % (item_count))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "   try:\n",
    "       bucket_name = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\n",
    "       s3_file_name = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n",
    "       resp = s3_client.get_object(Bucket=bucket_name, Key=s3_file_name)\n",
    "\n",
    "       ###########################################\n",
    "       # one of these methods should work for you.\n",
    "       # Method 1\n",
    "       df = pd.read_csv(resp['Body'], sep=',')\n",
    "       #\n",
    "       # Method 2\n",
    "       # df_s3_data = pd.read_csv(BytesIO(resp['Body'].read().decode('utf-8')))\n",
    "       ###########################################\n",
    "       print(df.head())\n",
    "\n",
    "   except Exception as err:\n",
    "      print(err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import logging\n",
    "from psycopg2 import sql\n",
    "\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    # Set the CloudWatch logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Secrets Manager settings\n",
    "    secret_name = \"db_credentials\"\n",
    "    region_name = \"ap-southeast-2\"\n",
    "\n",
    "    # RDS database settings\n",
    "    host = \"terraform-20230509135541811400000001.cz9iamvdbbik.ap-southeast-2.rds.amazonaws.com\"\n",
    "    user = \"gundalai\"\n",
    "    password = get_secret(region_name, secret_name)\n",
    "    database = \"data_store\"\n",
    "    connect_timeout = 5\n",
    "\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    df = get_dataframe(event, s3_client)\n",
    "\n",
    "    table_name, primary_key, values, attr_names, attr_names_dtypes = process_dataframe_for_sql(event, df)\n",
    "\n",
    "    conn = connect_database(host, user, password, database, connect_timeout)\n",
    "\n",
    "    create_table(conn, table_name, attr_names_dtypes, primary_key)\n",
    "\n",
    "    add_values_to_table(conn, table_name, values, attr_names)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def get_dataframe(event, s3_client):\n",
    "    \"\"\"\n",
    "    Create a dataframe from a csv file stored in a S3 bucket using the trigger event\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "       # Get the object from the bucket\n",
    "       bucket_name = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\n",
    "       file_name = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n",
    "       resp = s3_client.get_object(Bucket=bucket_name, Key=file_name)\n",
    "\n",
    "       # Create a dataframe from the csv file\n",
    "       df = pd.read_csv(resp['Body'], sep=',')\n",
    "\n",
    "       print(\"Created a dataframe from the stored file with the following head lines: \")\n",
    "       print(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "       print(f\"Error retrieving file from S3: {str(e)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_secret(region_name, secret_name, primary_key):\n",
    "    \"\"\"\n",
    "    Get a secret stored in Secrets Manager\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "        # Decrypts the secret string using the associated KMS key.\n",
    "        secret = get_secret_value_response['SecretString']\n",
    "        print(\"Secret retrieved\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        print(\"Error occurred:\", e)\n",
    "        raise e\n",
    "\n",
    "    return secret\n",
    "\n",
    "\n",
    "def connect_database(host, user, password, database, connect_timeout):\n",
    "    \"\"\"\n",
    "    Establish the database connection\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=rds_host, user=user_name, password=password, database=db_name, connect_timeout=5)\n",
    "        print (\"Successfully connected to PostgreSQL instanse\")\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        logger.error(\"ERROR: Unexpected error: Could not connect to PostgreSQL instance.\")\n",
    "        logger.error(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def process_dataframe_for_sql(event, df):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame and prepares it for a SQL query.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the table name based on the csv file's name\n",
    "    table_name = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n",
    "\n",
    "    # Define the first column of the dataframe as the primary key of the table\n",
    "    primary_key = df.columns[0]\n",
    "\n",
    "    # Define attribute's names/types based on the DataFrame's columns\n",
    "    attr_dict = {col: \"TEXT\" if dtype == \"object\" else \"INTEGER\" for col, dtype in df.dtypes.items()}\n",
    "\n",
    "    # Update the primary key\n",
    "    for k, v in attr_dict.items():\n",
    "        if k == primary_key:\n",
    "            v += ' PRIMARY KEY'\n",
    "            return\n",
    "\n",
    "    attr_names_dtypes = ', '.join(f\"{k} {v}\" for k, v in attr_dict.items()\n",
    "\n",
    "    attr_names = list(attr_dict.keys())\n",
    "\n",
    "    # Convert the DataFrame to a list of tuples\n",
    "    values = [tuple(row) for row in df.to_numpy()]\n",
    "\n",
    "    return table_name, primary_key, values, attr_names, attr_names_dtypes\n",
    "\n",
    "\n",
    "def create_table(conn, table_name, attr_names_dtypes)\n",
    "    \"\"\"\n",
    "    Create a table in the database if not already exists\n",
    "    \"\"\"\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        try:\n",
    "            cursor.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} ({attr_names_dtypes})\")\n",
    "            conn.commit()\n",
    "            print(f\"Succesfully created the table: {table_name}\")\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            return 1\n",
    "\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "def add_values_to_table(conn, table_name, values, attr_names)\n",
    "    \"\"\"\n",
    "    Add values to the table in the database\n",
    "    \"\"\"\n",
    "    item_count = 0\n",
    "\n",
    "    # Generate placeholders string. The placeholder represent one tuple of values.\n",
    "    placeholders = sql.SQL(', ').join(sql.Placeholder() * len(values[0]))\n",
    "\n",
    "    # SQL query to execute\n",
    "    query = sql.SQL(\"INSERT INTO {} ({}) VALUES ({})\").format(\n",
    "        sql.Identifier(table_name),\n",
    "        sql.SQL(', ').join(map(sql.Identifier, attr_names)),\n",
    "        placeholders\n",
    "    )\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        try:\n",
    "            cursor.executemany(query, values)\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            return 1\n",
    "        print(\"execute_many() done\")\n",
    "\n",
    "        cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "        logger.info(\"The following items have been added to the database:\")\n",
    "        for row in cursor:\n",
    "            item_count += 1\n",
    "            logger.info(row)\n",
    "        conn.commit()\n",
    "\n",
    "        print(\"Added %d items to rds PostgreSQL table\" % (item_count))\n",
    "\n",
    "        cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "\n",
    "        cursor.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_p18_19_5\n"
     ]
    }
   ],
   "source": [
    "s = \"03_processed/processed_p18_19_5.csv\"\n",
    "table_name = s.split('/')[-1].split('.')[0]\n",
    "print(table_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "kedro_data_processing_pipeline",
   "language": "python",
   "display_name": "Kedro (data_processing_pipeline)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}